#!/usr/bin/env python3
"""
SpecialEye Benchmark è¯„ä¼°è„šæœ¬ - ä½¿ç”¨ ILVR æ¨¡å‹

åŸºäº RoboRefer/Evaluation/test_benchmark.py æ”¹ç¼–ï¼Œé€‚é… Qwen2.5-VL ILVR æ¨¡å‹
"""
import argparse
import json
import os
import time
import torch
from PIL import Image
from transformers import Qwen2_5_VLForConditionalGeneration, AutoProcessor


def load_ilvr_model(model_dir: str, base_model_dir: str = None):
    """
    åŠ è½½ ILVR æ¨¡å‹å’Œ processor

    Args:
        model_dir: ILVR æ¨¡å‹ç›®å½•
        base_model_dir: å¤‡ç”¨çš„åŸºç¡€æ¨¡å‹ç›®å½•ï¼ˆç”¨äºåŠ è½½ processorï¼‰

    Returns:
        model, processor
    """
    print(f"ğŸ“¦ åŠ è½½æ¨¡å‹: {model_dir}")

    # åŠ è½½ processor
    processor = None

    # å°è¯•ä»å¤šä¸ªä½ç½®åŠ è½½ processor
    try:
        processor = AutoProcessor.from_pretrained(
            model_dir,
            trust_remote_code=True,
            local_files_only=True
        )
        print("âœ“ Processor ä»æ¨¡å‹ç›®å½•åŠ è½½æˆåŠŸ")
    except Exception as e1:
        print(f"âš ï¸  ä»æ¨¡å‹ç›®å½•åŠ è½½å¤±è´¥: {e1}")

        if base_model_dir and os.path.exists(base_model_dir):
            try:
                processor = AutoProcessor.from_pretrained(
                    base_model_dir,
                    trust_remote_code=True,
                    local_files_only=True
                )
                print(f"âœ“ Processor ä»åŸºç¡€æ¨¡å‹åŠ è½½æˆåŠŸ: {base_model_dir}")
            except Exception as e2:
                print(f"âš ï¸  ä»åŸºç¡€æ¨¡å‹åŠ è½½å¤±è´¥: {e2}")

        if processor is None:
            common_paths = [
                "/ytech_m2v_hdd/wangyuji/model/Qwen/Qwen2.5-VL-7B-Instruct",
                "/ytech_m2v_hdd/wangyuji/ckpt/ilvr_final/first",
            ]
            for path in common_paths:
                if os.path.exists(path):
                    try:
                        processor = AutoProcessor.from_pretrained(
                            path,
                            trust_remote_code=True,
                            local_files_only=True
                        )
                        print(f"âœ“ Processor ä»å¤‡ç”¨è·¯å¾„åŠ è½½æˆåŠŸ: {path}")
                        break
                    except Exception:
                        continue

    if processor is None:
        raise RuntimeError("âŒ æ— æ³•åŠ è½½ processorï¼Œè¯·æ£€æŸ¥æ¨¡å‹ç›®å½•æˆ–ç½‘ç»œè¿æ¥")

    # åŠ è½½æ¨¡å‹
    try:
        model = Qwen2_5_VLForConditionalGeneration.from_pretrained(
            model_dir,
            device_map="auto",
            torch_dtype=torch.bfloat16,
            trust_remote_code=True,
            attn_implementation="flash_attention_2",
            local_files_only=True
        )
    except Exception as e:
        print(f"âš ï¸  Flash Attention 2 åŠ è½½å¤±è´¥ï¼Œä½¿ç”¨ eager æ¨¡å¼...")
        model = Qwen2_5_VLForConditionalGeneration.from_pretrained(
            model_dir,
            device_map="auto",
            torch_dtype=torch.bfloat16,
            trust_remote_code=True,
            attn_implementation="eager",
            local_files_only=True
        )

    model.eval()
    print("âœ… æ¨¡å‹åŠ è½½å®Œæˆ")

    return model, processor


def query_ilvr_model(model, processor, image_paths, prompt, max_new_tokens=2048, temperature=0.0):
    """
    ä½¿ç”¨ ILVR æ¨¡å‹è¿›è¡Œæ¨ç†

    Args:
        model: ILVR æ¨¡å‹
        processor: Processor
        image_paths: å›¾ç‰‡è·¯å¾„åˆ—è¡¨
        prompt: é—®é¢˜æ–‡æœ¬
        max_new_tokens: æœ€å¤§ç”Ÿæˆtokenæ•°
        temperature: æ¸©åº¦å‚æ•°

    Returns:
        dict: {"raw_output": åŸå§‹è¾“å‡º, "cleaned_output": æ¸…ç†åçš„è¾“å‡º}
    """
    try:
        # åŠ è½½å›¾ç‰‡
        images = [Image.open(img_path).convert("RGB") for img_path in image_paths]

        # æ„å»ºå¯¹è¯å†…å®¹
        content = []
        for _ in images:
            content.append({"type": "image"})
        content.append({"type": "text", "text": prompt})

        conversations = [
            {"role": "user", "content": content}
        ]

        # åº”ç”¨ chat template
        prompt_text = processor.apply_chat_template(
            conversations,
            tokenize=False,
            add_generation_prompt=True
        )

        # å¤„ç†è¾“å…¥
        inputs = processor(
            text=[prompt_text],
            images=images,
            return_tensors="pt",
            padding=True
        )

        # ç§»åŠ¨åˆ°è®¾å¤‡
        inputs = {k: v.to(model.device) for k, v in inputs.items() if isinstance(v, torch.Tensor)}

        # ç”Ÿæˆé…ç½®
        gen_kwargs = {
            "max_new_tokens": max_new_tokens,
            "temperature": temperature,
            "top_p": 1.0,
            "do_sample": (temperature > 0)
        }

        # ç”Ÿæˆ
        with torch.inference_mode():
            output_ids = model.generate(**inputs, **gen_kwargs)

        # è§£ç ï¼ˆä¿ç•™ç‰¹æ®Štokensï¼‰
        raw_output = processor.batch_decode(
            output_ids,
            skip_special_tokens=False
        )[0].strip()

        # æå– assistant éƒ¨åˆ†
        import re
        match = re.search(
            r"<\|im_start\|>\s*assistant\s*(.*?)(?:<\|im_end\|>|$)",
            raw_output,
            flags=re.S | re.I
        )

        if match:
            assistant_content = match.group(1)
        else:
            assistant_content = raw_output

        # æ¸…ç†ç‰¹æ®Š tokens
        special_tokens = [
            "<|im_end|>", "<|endoftext|>", "<|eot_id|>",
            "<|latent_start|>", "<|latent_end|>", "<|latent_pad|>",
            "<|vision_start|>", "<|vision_end|>", "<|image_pad|>"
        ]
        cleaned_output = assistant_content
        for token in special_tokens:
            cleaned_output = cleaned_output.replace(token, "")

        cleaned_output = cleaned_output.strip()

        print(f"Model response: {cleaned_output[:200]}...")

        return {
            "raw_output": raw_output,
            "cleaned_output": cleaned_output
        }

    except Exception as e:
        print(f"âŒ Error: {e}")
        import traceback
        traceback.print_exc()
        time.sleep(1)
        return {
            "raw_output": f'Failed: Query Error - {e}',
            "cleaned_output": 'Failed: Query Error'
        }


def get_prompt(model_name, object_name, prompt, suffix):
    """
    æ„å»º promptï¼ˆæ ¹æ®ä»»åŠ¡ç±»å‹è°ƒæ•´ï¼‰

    å¯¹äº SpecialEye spatial reasoningï¼Œè¦æ±‚åœ¨ <answer> æ ‡ç­¾ä¸­è¾“å‡º JSON æ ¼å¼
    """
    # æ·»åŠ æ ¼å¼è¦æ±‚
    formatted_prompt = f"""{prompt}

Output the point coordinates in JSON format inside <answer></answer> tags.
For example:
<answer>
[
{{"point_2d": [x, y], "label": "point_1"}}
]
</answer>"""

#[
# {{"point_2d": [x, y], "label": "point_1"}}
# ]

# [(x, y)]
    return formatted_prompt


def eval_task(task_name, model_dir, base_model_dir, output_save_folder, max_new_tokens=2048):
    """
    è¯„ä¼°æŒ‡å®šä»»åŠ¡

    Args:
        task_name: ä»»åŠ¡åç§° (ä¾‹å¦‚: "Location", "Placement", "Unseen")
        model_dir: ILVR æ¨¡å‹ç›®å½•
        base_model_dir: åŸºç¡€æ¨¡å‹ç›®å½•ï¼ˆç”¨äºåŠ è½½processorï¼‰
        output_save_folder: è¾“å‡ºæ–‡ä»¶å¤¹
        max_new_tokens: æœ€å¤§ç”Ÿæˆtokenæ•°
    """
    benchmark_question_file = f"/ytech_m2v_hdd/wangyuji/data/JingkunAn/RefSpatial-Bench/{task_name}"

    # åŠ è½½æ¨¡å‹ï¼ˆåªåŠ è½½ä¸€æ¬¡ï¼‰
    model, processor = load_ilvr_model(model_dir, base_model_dir)

    # åŠ è½½é—®é¢˜
    question_file = f"{benchmark_question_file}/question.json"
    if not os.path.exists(question_file):
        print(f"âŒ é—®é¢˜æ–‡ä»¶ä¸å­˜åœ¨: {question_file}")
        return

    with open(question_file, "r") as f:
        questions = json.load(f)

    print(f"ğŸ“Š åŠ è½½äº† {len(questions)} ä¸ªé—®é¢˜")

    # åˆ›å»ºè¾“å‡ºè·¯å¾„
    model_name_short = os.path.basename(model_dir)
    output_path = f'{output_save_folder}/{model_name_short}/{task_name}.jsonl'
    os.makedirs(os.path.dirname(output_path), exist_ok=True)

    if os.path.exists(output_path):
        print(f'âš ï¸  {output_path} å·²å­˜åœ¨ï¼Œè·³è¿‡')
        return

    print(f"ğŸ’¾ è¾“å‡ºæ–‡ä»¶: {output_path}")

    # æ¨ç†å¹¶ä¿å­˜ç»“æœ
    with open(output_path, "w") as ans_file:
        for idx, question in enumerate(questions):
            # æ„å»ºå›¾ç‰‡è·¯å¾„
            image_paths = [f"{benchmark_question_file}/{question['rgb_path']}"]

            # æ£€æŸ¥å›¾ç‰‡æ˜¯å¦å­˜åœ¨
            if not os.path.exists(image_paths[0]):
                print(f"âš ï¸  å›¾ç‰‡ä¸å­˜åœ¨: {image_paths[0]}")
                continue

            # æ„å»º prompt
            instruction = get_prompt(
                model_dir,
                question["object"],
                question["prompt"],
                question["suffix"]
            )

            print(f"\n[{idx+1}/{len(questions)}] Processing question {question['id']}")
            print(f"Prompt: {instruction[:100]}...")

            # ç”Ÿæˆç­”æ¡ˆ
            model_output = query_ilvr_model(
                model,
                processor,
                image_paths,
                instruction,
                max_new_tokens=max_new_tokens,
                temperature=0.0
            )

            # ä¿å­˜ç»“æœï¼ˆåŒ…å«åŸå§‹è¾“å‡ºå’Œæ¸…ç†åçš„è¾“å‡ºï¼‰
            result = {
                "question_id": question["id"],
                "prompt": question["prompt"],
                "object_name": question["object"],
                "suffix": question["suffix"],
                "instruction": instruction,
                "text": model_output["cleaned_output"],  # æ¸…ç†åçš„è¾“å‡º
                "raw_output": model_output["raw_output"],  # åŸå§‹è¾“å‡ºï¼ˆåŒ…å«ç‰¹æ®Štokensï¼‰
                "model_id": model_dir,
                "rgb_path": question["rgb_path"],
                "mask_path": question["mask_path"],
                "category": question["category"],
                "step": question["step"]
            }

            ans_file.write(json.dumps(result, ensure_ascii=False) + "\n")
            ans_file.flush()

    print(f"\nâœ… ä»»åŠ¡ {task_name} å®Œæˆï¼")


def parse_args():
    parser = argparse.ArgumentParser(
        description="SpecialEye Benchmark è¯„ä¼° - ILVR æ¨¡å‹",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  # è¯„ä¼°å•ä¸ªä»»åŠ¡
  python test_specialeye_benchmark.py \\
    --model_dir /ytech_m2v_hdd/wangyuji/ckpt/ilvr_depth/step_2000 \\
    --task_name Location

  # è¯„ä¼°æ‰€æœ‰ä»»åŠ¡
  python test_specialeye_benchmark.py \\
    --model_dir /ytech_m2v_hdd/wangyuji/ckpt/ilvr_depth/step_2000 \\
    --task_name all

  # è‡ªå®šä¹‰è¾“å‡ºç›®å½•å’Œç”Ÿæˆé•¿åº¦
  python test_specialeye_benchmark.py \\
    --model_dir /ytech_m2v_hdd/wangyuji/ckpt/ilvr_final/covt_ilvr \\
    --task_name Location Placement \\
    --output_folder ./benchmark_results \\
    --max_new_tokens 4096
        """
    )

    parser.add_argument(
        "--model_dir",
        type=str,
        default="/ytech_m2v_hdd/wangyuji/ckpt/ilvr_final/covt_ilvr",
        help="ILVR æ¨¡å‹ç›®å½•è·¯å¾„"
    )
    parser.add_argument(
        "--base_model_dir",
        type=str,
        default="/ytech_m2v_hdd/wangyuji/model/Qwen/Qwen2.5-VL-7B-Instruct",
        help="åŸºç¡€æ¨¡å‹ç›®å½•ï¼ˆç”¨äºåŠ è½½ processorï¼‰"
    )
    parser.add_argument(
        "--task_name",
        type=str,
        nargs="+",
        default=['Location'],
        help="ä»»åŠ¡åç§°ï¼Œå¯é€‰: Location, Placement, Unseen, all"
    )
    parser.add_argument(
        "--output_folder",
        type=str,
        default='./benchmark_outputs',
        help="è¾“å‡ºæ–‡ä»¶å¤¹è·¯å¾„"
    )
    parser.add_argument(
        "--max_new_tokens",
        type=int,
        default=2048,
        help="æœ€å¤§ç”Ÿæˆ token æ•°"
    )

    return parser.parse_args()


if __name__ == '__main__':
    args = parse_args()

    print("="*60)
    print("ğŸš€ SpecialEye Benchmark è¯„ä¼° - ILVR æ¨¡å‹")
    print("="*60)
    print(f"æ¨¡å‹: {args.model_dir}")
    print(f"è¾“å‡º: {args.output_folder}")
    print(f"æœ€å¤§tokens: {args.max_new_tokens}")
    print("="*60)

    # å¤„ç†ä»»åŠ¡åˆ—è¡¨
    if args.task_name == ['all']:
        subtasks = ['Location', 'Placement', "Unseen"]
    else:
        subtasks = args.task_name

    # è¯„ä¼°æ¯ä¸ªä»»åŠ¡
    for task_name in subtasks:
        print(f'\n{"="*60}')
        print(f'ğŸ“‹ å¤„ç†ä»»åŠ¡: {task_name}')
        print(f'{"="*60}')

        eval_task(
            task_name=task_name,
            model_dir=args.model_dir,
            base_model_dir=args.base_model_dir,
            output_save_folder=args.output_folder,
            max_new_tokens=args.max_new_tokens
        )

    print(f'\n{"="*60}')
    print("ğŸ‰ æ‰€æœ‰ä»»åŠ¡å®Œæˆï¼")
    print(f'{"="*60}')
